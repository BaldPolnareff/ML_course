{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.express as px \n",
    "import plotly.graph_objects as go \n",
    "import seaborn as sns \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem statement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model a linear regression model to predict the price of a house based on its size, based on the following data:\n",
    "\n",
    "|`x`: **Size** [1000 sqft] |`y`: **Price** [$1000]  |\n",
    "|--------------------------|------------------------|\n",
    "|1.0                       |300.0                   |\n",
    "|2.0                       |500.0                   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor([1.0, 2.0])\n",
    "y_train = torch.tensor([300.0, 500.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_wb(x, w, b): \n",
    "    return w * x + b  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 200\n",
    "b = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = f_wb(x_train, w, b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the cost function\n",
    "\n",
    "In this situation, the cost function is the **mean squared error** (MSE) between the predicted and the actual values. The MSE is a suitable cost function for linear regression because it penalizes large errors. The MSE is defined as:\n",
    "\n",
    "$$ J(w, b) = \\displaystyle\\frac{1}{2m} \\sum_{i=0}^{m-1} (y_i - \\hat{y}_i)^2 $$\n",
    "\n",
    "where $m$ is the number of training examples, $y_i$ is the actual value of the $i$-th training example, and $\\hat{y}_i$ is the predicted value of the $i$-th training example, given by the linear function: \n",
    "\n",
    "$$ f_{w, b}(x_i) = w x_i + b $$\n",
    "\n",
    "where $w$ is the weight and $b$ is the bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([300., 500.]), tensor([300., 500.]))"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_hat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactively plot the linear regression model and the cost function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a plot with two subfigures. The first subfigure will show the linear regression model and the training data. The second subfigure will show the cost function as a function of the weight and bias. The cost function will be computed for a grid of values of the weight and bias."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a value of $b = 100$ provided an optimal solution from the previous exercise, we will fix it and only vary the weight $w$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set a fixed bias and a range of values for the weights, as well as compute the linear regression and the cost function for each value of the weight, which we will connect to the slider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set_style('darkgrid')\n",
    "#\n",
    "#def MSE(fun, w, b, x, y):\n",
    "#    m = x.shape[0]\n",
    "#    y_hat = fun(x, w, b)\n",
    "#    cost = 1/(2*m) * torch.sum((y_hat - y)**2)\n",
    "#    return cost\n",
    "#\n",
    "#def interact_plot_funcs(x_train, y_train):\n",
    "#    X = torch.tensor(x_train)\n",
    "#    Y = torch.tensor(y_train)\n",
    "#    \n",
    "#    def plot_funcs(w, X, Y):\n",
    "#        fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
    "#        \n",
    "#        y_hat = f_wb(X, w, 100)\n",
    "#        axs[0].scatter(X, Y, label=\"Training Data\")\n",
    "#        axs[0].plot(X, y_hat, label=\"Linear Regression\")\n",
    "#        axs[0].set_xlabel('x')\n",
    "#        axs[0].set_ylabel('y')\n",
    "#        axs[0].set_title('Linear Regression')\n",
    "#        axs[0].legend()\n",
    "#        \n",
    "#        w_vals = torch.linspace(0, 400, 1000)\n",
    "#        J_vals = torch.tensor([MSE(f_wb, w, 100, X, Y) for w in w_vals])\n",
    "#        axs[1].plot(w_vals, J_vals)\n",
    "#        axs[1].plot()\n",
    "#        axs[1].set_xlabel('w')\n",
    "#        axs[1].set_ylabel('J(w)')\n",
    "#        axs[1].set_title('Cost Function')\n",
    "#        \n",
    "#        plt.show()\n",
    "#    \n",
    "#    interact = ipywidgets.interact(plot_funcs, w=(0, 400, 1), X=ipywidgets.fixed(X), Y=ipywidgets.fixed(Y))\n",
    "#    return interact, (fig, axs)\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(fun, w, b, x, y):\n",
    "    m = x.shape[0]\n",
    "    y_hat = fun(x, w, b)\n",
    "    cost = 1/(2*m) * torch.sum((y_hat - y)**2)\n",
    "    return cost\n",
    "\n",
    "def interact_plot_funcs(x_train, y_train):\n",
    "    X = torch.tensor(x_train)\n",
    "    Y = torch.tensor(y_train)\n",
    "\n",
    "    def plot_funcs(X, Y, w):\n",
    "        f_wb = lambda x, w, b: w*x + b\n",
    "        y_hat = f_wb(X, w, 100)\n",
    "\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
    "        axs[0].plot(X.numpy(), Y.numpy(), 'o')\n",
    "        axs[0].plot(X.numpy(), y_hat.numpy(), '-')\n",
    "        axs[0].set_title('Linear Regression')\n",
    "        axs[0].set_xlabel('x')\n",
    "        axs[0].set_ylabel('y')\n",
    "\n",
    "        J_vals = torch.tensor([MSE(f_wb, w, 100, X, Y) for w in w_vals])\n",
    "        axs[1].plot(w_vals.numpy(), J_vals.numpy(), '-')\n",
    "        axs[1].scatter(w, MSE(f_wb, w, 100, X, Y), c='r', marker='o')\n",
    "        axs[1].set_title('Cost Function')\n",
    "        axs[1].set_xlabel('w')\n",
    "        axs[1].set_ylabel('J(w)')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    w_vals = torch.linspace(0, 400, 100)\n",
    "    interact = ipywidgets.interact(plot_funcs, X=ipywidgets.fixed(X), Y=ipywidgets.fixed(Y), w=(0, 400, 0.1))\n",
    "    return interact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144137/2714105261.py:8: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "/tmp/ipykernel_144137/2714105261.py:9: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7b824a81fe443493aa730debeb5a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=200.0, description='w', max=400.0), Output()), _dom_classes=('widget-iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact_plot_funcs(x_train, y_train)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
